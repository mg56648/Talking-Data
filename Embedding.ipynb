{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "#train_df = pd.read_csv('train.csv', nrows=40000000)\n",
    "#train_df = pd.read_csv('train_sample.csv')\n",
    "train_df = pd.read_csv('train_extra.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unkonwn_tag(col, train_df = train_df, test_df = test_df):\n",
    "    test_df.loc[~test_df[col].isin(train_df[col]),col] = 9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lowfreq_tag(col, train_df = train_df,test_df = test_df, N=3):\n",
    "    topN_address_list = train_df[col].value_counts()\n",
    "    topN_address_list = topN_address_list[topN_address_list <= N]\n",
    "    topN_address_list = topN_address_list.index\n",
    "    remove_list = train_df.loc[train_df[col].isin(topN_address_list), col]\n",
    "    print('remove:',len(remove_list))\n",
    "    print('reserve',len(train_df) - len(remove_list))\n",
    "    remove_list = 9999998\n",
    "    test_df.loc[test_df[col].isin(topN_address_list), col] = 9999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['time_t'] = df.click_time.str[11:13] + df.click_time.str[14:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove: 218\n",
      "reserve 119782\n",
      "remove: 63329\n",
      "reserve 56671\n",
      "remove: 600\n",
      "reserve 119400\n",
      "remove: 125\n",
      "reserve 119875\n",
      "remove: 39\n",
      "reserve 119961\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(['app','ip','device','os','channel'],[5,4,4,5,5]):\n",
    "    remove_lowfreq_tag(i,N=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['app','ip','device','os','channel']:\n",
    "    remove_unkonwn_tag(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def process_lable_encoder(col, train_df = train_df, test_df = test_df):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.hstack([train_df[col], test_df[col]]))\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_list = ['ip','app','device','os','channel','time_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing done\n"
     ]
    }
   ],
   "source": [
    "preprocess(train_df)\n",
    "preprocess(test_df)\n",
    "print(\"preprocessing done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label gen done\n"
     ]
    }
   ],
   "source": [
    "for i in coding_list:\n",
    "    process_lable_encoder(i)\n",
    "    \n",
    "print(\"label gen done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX gen done\n"
     ]
    }
   ],
   "source": [
    "MAX_IP = np.max(train_df.ip.max()) + 2 #39612 #277396\n",
    "MAX_DEVICE = np.max(train_df.device.max()) + 2 #299 #3475\n",
    "MAX_OS = np.max(train_df.os.max()) + 2 #161 #3475\n",
    "MAX_APP = np.max(train_df.app.max()) + 2 #214 #3475\n",
    "MAX_CHANNEL = np.max(train_df.channel.max()) + 2  #155\n",
    "MAX_TIME = np.max(train_df.time_t.max()) + 2 #24*60+1\n",
    "print(\"MAX gen done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_data(df):\n",
    "    X = {\n",
    "        'ip': np.array(df.ip),\n",
    "        'app': np.array(df.app),\n",
    "        'device': np.array(df.device),\n",
    "        'os': np.array(df.os),\n",
    "        'channel': np.array(df.channel),\n",
    "        'clicktime': np.array(df.time_t),\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bailey\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(lr=0.001, decay=0.0):\n",
    "    ip = Input(shape=[1], name=\"ip\")\n",
    "    app = Input(shape=[1], name=\"app\")\n",
    "    device = Input(shape=[1], name=\"device\")\n",
    "    os = Input(shape=[1], name=\"os\")\n",
    "    channel = Input(shape=[1], name=\"channel\")\n",
    "    clicktime = Input(shape=[1], name=\"clicktime\")\n",
    "\n",
    "    emb_ip = Embedding(MAX_IP, 64)(ip)\n",
    "    emb_device = Embedding(MAX_DEVICE, 16)(device)\n",
    "    emb_os= Embedding(MAX_OS, 16)(os)\n",
    "    emb_app = Embedding(MAX_APP, 16)(app)\n",
    "    emb_channel = Embedding(MAX_CHANNEL, 8)(channel)\n",
    "    emb_time = Embedding(MAX_TIME, 32)(clicktime)\n",
    "\n",
    "    main = concatenate([Flatten()(emb_ip), \n",
    "                        Flatten()(emb_device), \n",
    "                        Flatten()(emb_os),\n",
    "                        Flatten()(emb_app),\n",
    "                        Flatten()(emb_channel), \n",
    "                        Flatten()(emb_time)])\n",
    "    main = Dense(128,kernel_initializer='normal', activation=\"tanh\")(main)\n",
    "    main = Dropout(0.2)(main)\n",
    "    main = Dense(64,kernel_initializer='normal', activation=\"tanh\")(main)\n",
    "    main = Dropout(0.2)(main)    \n",
    "    main = Dense(32,kernel_initializer='normal', activation=\"relu\")(main)\n",
    "    output = Dense(1,activation=\"sigmoid\") (main)\n",
    "    #model\n",
    "    model = Model([ip, app, device, os, channel, clicktime], output)\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining  model...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "Y_train = train_df.is_attributed.values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df[coding_list], Y_train, test_size = 0.1, random_state= 1984, stratify = Y_train)\n",
    "X_train = get_keras_data(X_train[coding_list])\n",
    "X_valid = get_keras_data(X_valid[coding_list])\n",
    "\n",
    "print(\"Defining  model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  model to training examples...\n"
     ]
    }
   ],
   "source": [
    "# Model hyper parameters.\n",
    "BATCH_SIZE = 1024*2\n",
    "epochs = 1\n",
    "\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(train_df['ip']) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "model = get_model(lr=lr_init, decay=lr_decay)\n",
    "\n",
    "print(\"Fitting  model to training examples...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108000 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "108000/108000 [==============================] - 6s 60us/step - loss: 0.6902 - val_loss: 0.1935\n",
      "Valid AUC: 0.9520\n"
     ]
    }
   ],
   "source": [
    "cw = {0: 1, 1: 3}\n",
    "for i in range(1):\n",
    "    model.fit(\n",
    "            X_train, y_train, epochs=1, batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_valid, y_valid), verbose=1,class_weight=cw\n",
    "    )\n",
    "    y_val_pred = model.predict(X_valid)[:, 0]\n",
    "    print('Valid AUC: {:.4f}'.format(roc_auc_score(y_valid, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   click_id  is_attributed\n",
      "0         0       0.147738\n",
      "1         1       0.128125\n",
      "2         2       0.069657\n",
      "3         3       0.080375\n",
      "4         4       0.096859\n"
     ]
    }
   ],
   "source": [
    "X_test = get_keras_data(test_df[coding_list])\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id']\n",
    "sub['is_attributed'] = preds\n",
    "sub.to_csv('embedding2.csv', index=False)\n",
    "print(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
